# -*- coding: utf-8 -*-
"""Final WELFake.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19BxCffLXq9pDCBpS359bfiPCw--73wno
"""

from google.colab import drive
drive.mount('/content/drive')

! pip install contractions

! pip install langdetect

! pip install wordcloud

import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
import re
import contractions
import nltk
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer
from nltk.corpus import stopwords, words
from langdetect import detect
from langdetect import detect, DetectorFactory
from wordcloud import WordCloud
from textblob import TextBlob
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

nltk.download('wordnet')
nltk.download('omw-1.4')
nltk.download('words')
nltk.download('stopwords')
nltk.download('punkt')

df = pd.read_csv('/content/drive/MyDrive/Fake_News/WELFake_Dataset.csv', index_col=False)
df.head(10)

"""This dataset contains 4 columns and 72134 rows, in which I wished to see through the first 10."""

#df.info()
#dg = df.reset_index(drop=True)
df.isnull().sum()
df.drop(["Unnamed: 0"], axis=1, inplace=True)

df.isnull().sum().plot(kind="barh")
plt.show()

"""Above plot shows how much of NaN values present in title and text column"""

null = df.isnull().any(axis=1)
null_rows = df[null]

print(null_rows)

"""This shows the total title which have NaN values, which we'll be dropping in next step"""

df.dropna(subset=['title'], inplace=True)
df.dropna(subset=['text'], inplace=True)

"""#EDA"""

y = df.label
print(f'Ratio of real and fake news:')
y.value_counts(normalize=True).rename({1: 'real', 0: 'fake'})

"""Percentage of Real and Fake News:

* 51.03% : Real
* 48.96% : Fake
"""

DetectorFactory.seed = 0

def detect_language(text):
    try:
        return detect(text)
    except:
        return "Error"

df['language'] = df['text'].apply(detect_language)
language_counts = df['language'].value_counts()

english_count = language_counts.get('en', 0)
non_english_count = sum(language_counts) - english_count

# Data for plotting
labels = 'English', 'Non-English'
sizes = [english_count, non_english_count]

# Plotting
fig1, ax1 = plt.subplots()
ax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
ax1.axis('equal')

plt.show()

"""In this pie chart, it shows the amount of English and Non-English text present in 'text' column.

From the visualization, it is clear that the non-english content is very small compared to English i.e. 1.9% of the tootal conten. So we can keep neglect this as it'll will not affect our model
"""

DetectorFactory.seed = 0

def detect_language(title):
    try:
        return detect(title)
    except:
        return "Error"

df['language'] = df['title'].apply(detect_language)
language_counts = df['language'].value_counts()

english_count = language_counts.get('en', 0)
non_english_count = sum(language_counts) - english_count

# Data for plotting
labels = 'English', 'Non-English'
sizes = [english_count, non_english_count]

# Plotting
fig1, ax1 = plt.subplots()
ax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
ax1.axis('equal')

plt.show()

"""Similar as text column pie chart, the non-english class isn't outweighing the other."""

sns.countplot(x='label', data=df)
plt.xticks([0, 1], ['Fake', 'Real'])
plt.show()

bins = np.linspace(0, 200, 40)

df['title_len'] = df['title'].apply(len) #calculating the length of the title
df['text_len'] = df['text'].apply(len) #calculating the length of the text column
df['total_len'] = df['title_len'] + df['text_len'] #adding the total length of title and text columnt

#bins = np.linspace(0, df['total_len'].max(), 40)

plt.hist(df[df["label"] == 1]["total_len"], bins, alpha=0.5, label="Real", color="red")
plt.hist(df[df["label"] == 0]["total_len"], bins, alpha=0.5, label="Fake", color="green")
plt.legend(loc="upper right")
plt.xlabel('Length of Processed Title')
plt.ylabel('Number of Articles')
plt.title('Distribution of Article Title Lengths by Class')
plt.show()

"""Text length analysis;
Comparing the length of fake and real news articles.
And we can see there is quite notable difference between real and fake news, real news is a bit longer than fake news.
"""

df

df["title_text"] = df["title"] + df["text"] #Adding text and title colums into one column : 'title_text'

df

"""# Visualization of news title"""

titles = ' '.join(title for title in df['title'])
wordcloud = WordCloud(
    background_color='white',
    max_words=300,
    width=800,
    height=400,
).generate(titles)

plt.figure(figsize=(10, 8))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.show()

"""From the above visualization we can infer that most of the news title is related to elections and some of the big leader's names around the world."""

# Extracting 2 dataframes from df(dataset) based on the label: 0 & 1 which are fake and real news

fake_news = df[df['label'] == 0]
real_news = df[df['label'] == 1]

real_news

fake_news

"""#Visualization of only Fake News of title_text column"""

fake_texts = ' '.join(text for text in fake_news['title_text'])
wordcloud = WordCloud(
    background_color='white',
    max_words=300,
    width=800,
    height=400,
).generate(fake_texts)

plt.figure(figsize=(10, 8))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.show()

"""# Visualization of only Real News of title_text column"""

real_texts = ' '.join(text for text in real_news['title_text'])
wordcloud = WordCloud(
    background_color='white',
    max_words=300,
    width=800,
    height=400,
).generate(real_texts)

plt.figure(figsize=(10, 8))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.show

plt.figure(figsize=(12, 6))
plt.hist(fake_news['total_len'], bins=40, alpha=0.5, label='Fake News', color='red')
plt.hist(real_news['total_len'], bins=40, alpha=0.5, label='Real News', color='green')
plt.xlabel('Text Length (Number of Words)')
plt.ylabel('Frequency')
plt.title('Distribution of Text Lengths in Fake and Real News')
plt.legend()
plt.show()

def calculate_sentiment_raw(text):
    return TextBlob(text).sentiment.polarity

# Assuming 'title' is a column with raw text
df['sentiment_raw'] = df['title'].apply(calculate_sentiment_raw)

# Plotting sentiment distributions for raw text
plt.figure(figsize=(12, 6))
sns.histplot(df[df['label'] == 0]['sentiment_raw'], color='red', label='Fake News', kde=True)
sns.histplot(df[df['label'] == 1]['sentiment_raw'], color='green', label='Real News', kde=True)
plt.xlabel('Sentiment Polarity')
plt.ylabel('Frequency')
plt.title('Sentiment Polarity Distribution in Raw Titles')
plt.legend()
plt.show()

"""* Visualization of sentiment polarity distribution of raw titles, separated into fake and real news categories.
* It appears that the majorty of titles from both categories are centered around a sentiment polarity score close to zero which suggests a neutral tone, which is common for news titles.
"""

def calculate_sentiment_raw(text):
    return TextBlob(text).sentiment.polarity

# Assuming 'title' is a column with raw text
df['sentiment_raw'] = df['text'].apply(calculate_sentiment_raw)

# Plotting sentiment distributions for raw text
plt.figure(figsize=(12, 6))
sns.histplot(df[df['label'] == 0]['sentiment_raw'], color='red', label='Fake News', kde=True)
sns.histplot(df[df['label'] == 1]['sentiment_raw'], color='green', label='Real News', kde=True)
plt.xlabel('Sentiment Polarity')
plt.ylabel('Frequency')
plt.title('Sentiment Polarity Distribution in Raw Text')
plt.legend()
plt.show()

"""* This histogram visualizes the sentiment polarity distribution of the text column, similar to the previous histogram, this graph is centered around a sentiment polarity score close to zero.

#Pre-processing
"""

#df.isnull().sum().plot(kind="barh")
#plt.show()

class TextProcessor:
    def __init__(self):
        self.stemmer = PorterStemmer()
        self.lemmatizer = WordNetLemmatizer()
        self.stopWords = set(stopwords.words('english'))
        self.englishWords = set(nltk.corpus.words.words())
        self.url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'

    def url_count(self, text): #Counts the number of URLs
        return len(re.findall(self.url_pattern, text))

    def remove_urls(self, text): #Remove URLs
        return re.sub(self.url_pattern, '', text)

    #def to_lowercase(self, text):
        #return [token.lower() for token in text]

    def remove_contraction(self, text): #Expands contractions in the text (i.e don't to do not)
        return ' '.join([contractions.fix(word) for word in text.split()])

    def clean_tokenize_text(self, text): #Removes non_alphanumeric characters and tokenizes the text into words
        cleaned_text = re.sub(r'[^a-zA-Z0-9\s]', '', text)
        cleaned_text = re.sub(r',+', ' ', cleaned_text)
        return word_tokenize(cleaned_text)

    #def stem(self, tokens):
        #return [self.stemmer.stem(token) for token in tokens]

    def lemmatize(self, tokens): #Reduces each token to its base form using WordNet
        return [self.lemmatizer.lemmatize(token) for token in tokens]

    def remove_stopWords(self, tokens): #Removes common stopwords from tokens
        return [w for w in tokens if w not in self.stopWords]

"""Custom well mannered class which consist of a comprehensive set of tools for text pre-processing, which includes: Removing url, ciontraction, tokenization, lemmatization and removing stopwords.

We used lemmatization instead of stemming because stemming just simply removed the only last 3 letters of the token which in our dataset introduced non-english words, as lemmatization reduces the words back to its root word.
"""

text_processor = TextProcessor()

def process_text_column(column):
    def process(text):
        original_text = text  # Original text
        #print(f"Original text: {original_text}")  # Debug print
        text = text_processor.remove_urls(text).lower()
        #print(f"After remove_urls: {text}")  # Debug print

        # Check if text is empty or not a string
        if not isinstance(text, str) or not text.strip():
            print(f"Skipping due to empty or non-string text: {original_text}")  # Debug print
            return []

        try:
            # Skip non-English text
            if detect(text) != 'en':
                print(f"Skipping non-English text: {original_text}")  # Debug print
                return []
        except Exception as e:
            print(f"Error detecting language for text: {original_text}. Error: {e}")  # Debug print
            return []

        text = text_processor.remove_contraction(text)
        #print(f"After remove_contraction: {text}")  # Debug print
        tokens = text_processor.clean_tokenize_text(text)
        #print(f"After clean_tokenize_text: {tokens}")  # Debug print
        tokens = text_processor.remove_stopWords(tokens)
        #print(f"After remove_stopWords: {tokens}")  # Debug print

        #tokens = text_processor.stem(tokens)
        #print(f"After stem: {tokens}")

        tokens = text_processor.lemmatize(tokens)
        print(f"After lemmatize: {tokens}")  # Debug print
        return tokens

    return column.apply(process)

"""Defined a function which processes text data column-wise, as it is made to work with our custom 'TextProcessor' class. It consist of some debug code which when executed gives all the modifications our dataset will go through while doing this pre-processing."""

#df_sampled = df.sample(frac=0.1, random_state=42)

df['processed_title'] = process_text_column(df['title'])

df['processed_text'] = process_text_column(df_sampled['text'])

df['processed_title']

df_sampled = df.sample(frac=0.5, random_state=42) # taking only 50% of the dataset for further model implementation

df['processed_title_str'] = df_sampled['processed_title'].apply(lambda tokens: ' '.join(tokens)) #Adding tokens of the processed_tiltle to join them into strings for further implementation.

df_sampled

"""# SVM"""

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.svm import SVC
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler

svm_pipeline = make_pipeline(
    CountVectorizer(),
    StandardScaler(with_mean=False),
    SVC(kernel='linear')
)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(df_sampled['processed_title_str'], df_sampled['label'], test_size=0.2, random_state=42)

"""Setting up an SVM pipeline with a 'CountVectorizer' and 'StandardScaler', where the 'make_pipeline' function creates a pipeline which first vectorizes the data then scales the feature using 'StandardScaler, and in last applies an SVM with a linear kernel for classification."""

X_train

svm_pipeline.fit(X_train, y_train)

"""Training the SVM pipeline"""

y_pred = svm_pipeline.predict(X_test)
print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
print(classification_report(y_test, y_pred))

"""#Confusion Matrix"""

plt.figure(figsize = (8,6))

sns.heatmap(confusion_matrix(y_test,y_pred), annot=True,
            fmt='', cmap='Blues')

plt.xlabel('Predicted Labels')
plt.ylabel('Real Labels')

"""#Naive Bayes"""

vectorizer = CountVectorizer(max_features=5000)  # Initialize CountVectorizer
X_sampled = vectorizer.fit_transform(df_sampled['processed_title_str'])  # Vectorize the text data
y_sampled = df_sampled['label']  # Labels

# Split the sampled data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_sampled, y_sampled, test_size=0.2, random_state=42)

# Train a Naive Bayes classifier
clf = MultinomialNB()
clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

# Calculate accuracy and print the classification report
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print(accuracy)
print(report)

"""#Confusion Matrix"""

plt.figure(figsize = (8,6))

sns.heatmap(confusion_matrix(y_test,y_pred), annot=True,
            fmt='', cmap='Blues')

plt.xlabel('Predicted Labels')
plt.ylabel('Real Labels')

